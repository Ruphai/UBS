
Epoch 0:   0%|          | 0/85 [00:00<?, ?it/s]
wandb: WARNING Serializing object of type DataFrame that is 929061 bytes
  | Name              | Type     | Params
-----------------------------------------------
0 | feature_extractor | ResNet   | 11.7 M
1 | classifier        | Linear   | 2.0 K
2 | train_accuracy    | Accuracy | 0
3 | train_f1          | F1       | 0
4 | val_accuracy      | Accuracy | 0
5 | val_f1            | F1       | 0
6 | val_fbeta         | FBeta    | 0
7 | test_accuracy     | Accuracy | 0
8 | test_f1           | F1       | 0
9 | test_fbeta        | FBeta    | 0
-----------------------------------------------
2.0 K     Trainable params
11.7 M    Non-trainable params
11.7 M    Total params
23.383    Total estimated model params size (MB)
C:\Users\rufai\anaconda3\lib\site-packages\pytorch_lightning\trainer\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
C:\Users\rufai\anaconda3\lib\site-packages\pytorch_lightning\trainer\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.









Epoch 0:  74%|███████▍  | 63/85 [00:20<00:07,  3.10it/s, loss=0.33, v_num=djmx, Train_loss_step=0.259]


Validating:  69%|██████▉   | 18/26 [00:05<00:02,  3.40it/s]









Epoch 1:  71%|███████   | 60/85 [00:18<00:07,  3.30it/s, loss=0.251, v_num=djmx, Train_loss_step=0.156, Val_loss=0.262, Acc_val=0.898, Train_loss_epoch=0.537]



Validating:  69%|██████▉   | 18/26 [00:05<00:02,  3.02it/s]










Epoch 2:  71%|███████   | 60/85 [00:19<00:07,  3.14it/s, loss=0.252, v_num=djmx, Train_loss_step=0.248, Val_loss=0.228, Acc_val=0.919, Train_loss_epoch=0.278]















Epoch 3:  73%|███████▎  | 62/85 [00:21<00:08,  2.87it/s, loss=0.273, v_num=djmx, Train_loss_step=0.474, Val_loss=0.212, Acc_val=0.922, Train_loss_epoch=0.251]



Validating:  88%|████████▊ | 23/26 [00:07<00:00,  3.32it/s]










Epoch 4:  73%|███████▎  | 62/85 [00:21<00:07,  2.92it/s, loss=0.233, v_num=djmx, Train_loss_step=0.0668, Val_loss=0.209, Acc_val=0.919, Train_loss_epoch=0.242]



Validating:  85%|████████▍ | 22/26 [00:07<00:01,  3.26it/s]










Epoch 5:  73%|███████▎  | 62/85 [00:20<00:07,  3.04it/s, loss=0.254, v_num=djmx, Train_loss_step=0.268, Val_loss=0.207, Acc_val=0.920, Train_loss_epoch=0.236]



Validating:  88%|████████▊ | 23/26 [00:07<00:00,  3.30it/s]
Epoch 5, global step 353: Val_loss reached 0.19986 (best 0.19986), saving model to "c:\Users\rufai\Downloads\assignment-instructions\assignment\Oil Palm Classification\dlk1djmx\checkpoints\./best-model/OilPalmRes/-epoch=05--val_loss=0.00.ckpt" as top 5
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
wandb: WARNING Serializing object of type DataFrame that is 929061 bytes
C:\Users\rufai\anaconda3\lib\site-packages\pytorch_lightning\trainer\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.





Testing: 100%|██████████| 36/36 [00:10<00:00,  4.50it/s]\Test Accuracy: 0.0000, F1 Score: 0.0000FBeta Score: 0.0000
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'Acc_test': 0.9231770634651184,
 'Test_F1': 0.8065330982208252,
 'Test_FBeta': 0.8065330982208252}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 36/36 [00:10<00:00,  3.56it/s]
C:\Users\rufai\anaconda3\lib\site-packages\torchmetrics\utilities\prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)
C:\Users\rufai\anaconda3\lib\site-packages\torchmetrics\utilities\prints.py:36: UserWarning: The ``compute`` method of metric F1 was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)
C:\Users\rufai\anaconda3\lib\site-packages\torchmetrics\utilities\prints.py:36: UserWarning: The ``compute`` method of metric FBeta was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)
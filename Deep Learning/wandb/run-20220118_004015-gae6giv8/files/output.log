wandb: WARNING Serializing object of type DataFrame that is 929061 bytes
  | Name              | Type     | Params
-----------------------------------------------
0 | feature_extractor | ResNet   | 11.7 M
1 | classifier        | Linear   | 2.0 K
2 | train_accuracy    | Accuracy | 0
3 | train_f1          | F1       | 0
4 | val_accuracy      | Accuracy | 0
5 | val_f1            | F1       | 0
6 | val_fbeta         | FBeta    | 0
7 | test_accuracy     | Accuracy | 0
8 | test_f1           | F1       | 0
9 | test_fbeta        | FBeta    | 0
-----------------------------------------------
2.0 K     Trainable params
11.7 M    Non-trainable params
11.7 M    Total params
23.383    Total estimated model params size (MB)
C:\Users\rufai\anaconda3\lib\site-packages\pytorch_lightning\callbacks\model_checkpoint.py:631: UserWarning: Checkpoint directory C:\Users\rufai\Downloads\assignment-instructions\assignment\best-model\OilPalmRes exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
C:\Users\rufai\anaconda3\lib\site-packages\pytorch_lightning\trainer\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
C:\Users\rufai\anaconda3\lib\site-packages\pytorch_lightning\trainer\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(







Epoch 0:  75%|███████▌  | 64/85 [00:16<00:05,  3.83it/s, loss=0.287, v_num=giv8, Train_loss_step=0.324]


Validating:  85%|████████▍ | 22/26 [00:05<00:01,  3.88it/s]








Epoch 1:  74%|███████▍  | 63/85 [00:16<00:05,  3.71it/s, loss=0.234, v_num=giv8, Train_loss_step=0.202, Val_loss=0.262, Acc_val=0.893, Train_loss_epoch=0.352]


Validating:  73%|███████▎  | 19/26 [00:04<00:01,  3.73it/s]








Epoch 2:  74%|███████▍  | 63/85 [00:16<00:05,  3.72it/s, loss=0.232, v_num=giv8, Train_loss_step=0.392, Val_loss=0.242, Acc_val=0.908, Train_loss_epoch=0.257]


Validating:  73%|███████▎  | 19/26 [00:05<00:01,  3.93it/s]








Epoch 3:  74%|███████▍  | 63/85 [00:16<00:05,  3.88it/s, loss=0.224, v_num=giv8, Train_loss_step=0.0994, Val_loss=0.238, Acc_val=0.914, Train_loss_epoch=0.245]


Validating:  73%|███████▎  | 19/26 [00:04<00:01,  3.88it/s]








Epoch 4:  74%|███████▍  | 63/85 [00:15<00:05,  3.95it/s, loss=0.214, v_num=giv8, Train_loss_step=0.158, Val_loss=0.235, Acc_val=0.913, Train_loss_epoch=0.234]


Validating:  81%|████████  | 21/26 [00:05<00:01,  4.17it/s]







Epoch 5:  71%|███████   | 60/85 [00:14<00:06,  4.02it/s, loss=0.21, v_num=giv8, Train_loss_step=0.149, Val_loss=0.236, Acc_val=0.918, Train_loss_epoch=0.233]


Validating:  69%|██████▉   | 18/26 [00:04<00:01,  4.25it/s]

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
wandb: WARNING Serializing object of type DataFrame that is 929061 bytes
C:\Users\rufai\anaconda3\lib\site-packages\pytorch_lightning\trainer\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(




Testing: 100%|██████████| 36/36 [00:11<00:00,  3.92it/s]\Test Accuracy: 0.0000, F1 Score: 0.0000FBeta Score: 0.0000
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'Acc_test': 0.9201388955116272,
 'Test_F1': 0.7998999357223511,
 'Test_FBeta': 0.7998999357223511}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 36/36 [00:11<00:00,  3.26it/s]
C:\Users\rufai\anaconda3\lib\site-packages\torchmetrics\utilities\prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)
C:\Users\rufai\anaconda3\lib\site-packages\torchmetrics\utilities\prints.py:36: UserWarning: The ``compute`` method of metric F1 was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)
C:\Users\rufai\anaconda3\lib\site-packages\torchmetrics\utilities\prints.py:36: UserWarning: The ``compute`` method of metric FBeta was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)
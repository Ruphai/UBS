wandb: WARNING Serializing object of type DataFrame that is 929061 bytes
  | Name              | Type     | Params
-----------------------------------------------
0 | feature_extractor | ResNet   | 11.7 M
1 | classifier        | Linear   | 2.0 K
2 | train_accuracy    | Accuracy | 0
3 | train_f1          | F1       | 0
4 | val_accuracy      | Accuracy | 0
5 | val_f1            | F1       | 0
6 | val_fbeta         | FBeta    | 0
7 | test_accuracy     | Accuracy | 0
8 | test_f1           | F1       | 0
9 | test_fbeta        | FBeta    | 0
-----------------------------------------------
2.0 K     Trainable params
11.7 M    Non-trainable params
11.7 M    Total params
23.383    Total estimated model params size (MB)
C:\Users\rufai\anaconda3\lib\site-packages\pytorch_lightning\trainer\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
C:\Users\rufai\anaconda3\lib\site-packages\pytorch_lightning\trainer\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(








Epoch 0:  69%|██████▉   | 59/85 [00:18<00:08,  3.13it/s, loss=0.35, v_num=lf8l, Train_loss_step=0.296]



Validating:  81%|████████  | 21/26 [00:06<00:01,  3.96it/s]








Epoch 1:  72%|███████▏  | 61/85 [00:16<00:06,  3.71it/s, loss=0.254, v_num=lf8l, Train_loss_step=0.274, Val_loss=0.289, Acc_val=0.890, Train_loss_epoch=0.599]











Epoch 2:  71%|███████   | 60/85 [00:16<00:06,  3.70it/s, loss=0.273, v_num=lf8l, Train_loss_step=0.240, Val_loss=0.262, Acc_val=0.908, Train_loss_epoch=0.268]



Validating:  69%|██████▉   | 18/26 [00:05<00:02,  3.32it/s]










Epoch 3:  74%|███████▍  | 63/85 [00:19<00:06,  3.24it/s, loss=0.216, v_num=lf8l, Train_loss_step=0.292, Val_loss=0.242, Acc_val=0.916, Train_loss_epoch=0.239]


Validating:  81%|████████  | 21/26 [00:05<00:01,  4.08it/s]








Epoch 4:  71%|███████   | 60/85 [00:15<00:06,  3.83it/s, loss=0.195, v_num=lf8l, Train_loss_step=0.114, Val_loss=0.236, Acc_val=0.914, Train_loss_epoch=0.221]


Validating:  73%|███████▎  | 19/26 [00:05<00:01,  3.93it/s]








Epoch 5:  71%|███████   | 60/85 [00:15<00:06,  3.83it/s, loss=0.204, v_num=lf8l, Train_loss_step=0.120, Val_loss=0.234, Acc_val=0.921, Train_loss_epoch=0.214]


Validating:  69%|██████▉   | 18/26 [00:04<00:01,  4.07it/s]
Epoch 5, global step 353: Val_loss reached 0.22910 (best 0.22910), saving model to "c:\Users\rufai\Downloads\assignment-instructions\assignment\Oil Palm Classification\2l59lf8l\checkpoints\./best-model/OilPalmRes/-epoch=05--val_loss=0.00.ckpt" as top 5
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
wandb: WARNING Serializing object of type DataFrame that is 929061 bytes
C:\Users\rufai\anaconda3\lib\site-packages\pytorch_lightning\trainer\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.





Testing: 100%|██████████| 36/36 [00:09<00:00,  4.71it/s]\Test Accuracy: 0.0000, F1 Score: 0.0000FBeta Score: 0.0000
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'Acc_test': 0.9210069179534912,
 'Test_F1': 0.7944018840789795,
 'Test_FBeta': 0.7944018840789795}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 36/36 [00:09<00:00,  3.71it/s]
C:\Users\rufai\anaconda3\lib\site-packages\torchmetrics\utilities\prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)
C:\Users\rufai\anaconda3\lib\site-packages\torchmetrics\utilities\prints.py:36: UserWarning: The ``compute`` method of metric F1 was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)
C:\Users\rufai\anaconda3\lib\site-packages\torchmetrics\utilities\prints.py:36: UserWarning: The ``compute`` method of metric FBeta was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)